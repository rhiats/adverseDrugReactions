{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15DL5TZ8KCnka9QwcFaEux50ceq_nlu9x",
      "authorship_tag": "ABX9TyMjJoKKShSFGkxLIDqQhdC7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Parse PHEE Data**\n",
        "\n",
        "PHEE data is stored in .txt files and .ann files, which are parsed and then stored in a dataframe.\n",
        "\n",
        "The dataframe with the data is exported as a '.pkl'\n",
        "file.\n",
        "\n",
        "**Important Notes for Running Notebook:**\n",
        "\n",
        "\n",
        "*   Need Clean Data to be saved in a directory, 'Input'\n",
        "*   Need to have a directory, 'Output'\n",
        "\n"
      ],
      "metadata": {
        "id": "qmQ0dLFwmTle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n-n_U3cymUOL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Functions**\n",
        "\n",
        "\n",
        "\n",
        "1.   **parse_txt_file**: Parse '.txt' files\n",
        "2.   **parse_ann_file**: Parse '.txt' files\n",
        "3.   **Merge**: Helper function to merge two \n",
        "dictionaries\n",
        "4.   **pkl_load_dict**: Helper function to load dictionaries from pkl file\n",
        "5.   **df_creation**: Create df of raw data and save for future analysis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GXvXZtKUs6qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_txt_file(input_path,output_path):\n",
        "  \"\"\"\n",
        "    Parse the text files and save the data to .pkl file\n",
        "\n",
        "    @p:\n",
        "    input_path (str): Path of the directory with input data\n",
        "    output_path (str): Path of the directory to save pkl file\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  temp_dict={}\n",
        "\n",
        "  for file_name in glob.glob(input_path + \"/*.txt\"):\n",
        "    id=file_name.split('.')[0].split('/')[-1]\n",
        "\n",
        "    with open(file_name) as f:\n",
        "      lines=f.readlines()[0]\n",
        "    \n",
        "    temp_dict[id]=lines\n",
        "\n",
        "    with open(output_path, 'wb') as handle:\n",
        "      pickle.dump(temp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def parse_ann_file(input_path,output_path):\n",
        "  \"\"\"\n",
        "    Parse the ann files and save the specific key to .pkl file\n",
        "\n",
        "    @p:\n",
        "    input_path (str): Path of the directory with input data\n",
        "    output_path (str): Path of the directory to save pkl file\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  label_lst=['Subject','Negation_cue',\n",
        "              'Potential_therapeutic_event',\n",
        "              'Drug','Effect','Adverse_event',\n",
        "              'Race','Age','Gender',\n",
        "              'Population','Disorder','Duration',\n",
        "              'Time_elapsed','Route','Freq',\n",
        "              'Dosage','Combination.Drug','Treat-Disorder',\n",
        "             'Treatment','Severity_cue','Severity'\n",
        "             ,'Speculation_cue','Sub-Disorder',\n",
        "             ]\n",
        "\n",
        "\n",
        "\n",
        "  id_list=[]\n",
        "\n",
        "  for l in label_lst:\n",
        "    temp_dict={}\n",
        "\n",
        "    for file_name in glob.glob(input_path + \"/*.ann\"):\n",
        "      id=file_name.split('.')[0].split('/')[-1]\n",
        "\n",
        "      with open(file_name, 'r') as document_anno_file:\n",
        "        lines = document_anno_file.readlines()\n",
        "\n",
        "        temp_lst=[]\n",
        "\n",
        "        for line in lines:\n",
        "          standoff_line=line.split(\"\\t\")\n",
        "          standoff_line.pop(0)\n",
        "\n",
        "          identifier=standoff_line[0].split()[0].strip()\n",
        "\n",
        "          if identifier=='Severity': \n",
        "            s=standoff_line[0].split(\" \")\n",
        "            temp_lst.append(s[2].strip())\n",
        "          elif identifier==l: temp_lst.append(standoff_line[1].strip())\n",
        "\n",
        "        temp_lst_str='||'.join(temp_lst)\n",
        "        temp_dict[id]=temp_lst_str\n",
        "\n",
        "    with open(output_path+'_{}.pickle'.format(l), 'wb') as handle:\n",
        "      pickle.dump(temp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def Merge(dict1, dict2):\n",
        "  \"\"\"\n",
        "    Add the contents of dict2 to dict1\n",
        "\n",
        "    @P:\n",
        "    dict1 (dict): Dictionary that has info added to it\n",
        "    dict2 (dict): Dictionary that has the contents to add to dict 1\n",
        "  \"\"\"\n",
        "  dict2.update(dict1)\n",
        "  return dict2\n",
        "\n",
        "def pkl_load_dict(filename):\n",
        "  \"\"\"\n",
        "    Load the dictionary data from a pickle file into a variable\n",
        "\n",
        "    @P:\n",
        "    filename (str): Name of the pkl file\n",
        "    varname : Name of the df to save the pkl data\n",
        "\n",
        "    @R:\n",
        "    varname : Containing the pkl data\n",
        "  \"\"\"\n",
        "\n",
        "  with open(filename, 'rb') as handle:\n",
        "      df = pickle.load(handle)\n",
        "\n",
        "  return df\n",
        "\n",
        "def df_creation(df_data,Merge,output_path):\n",
        "  \"\"\"\n",
        "    Add the data from the ann to the dataframe with the text\n",
        "\n",
        "    @P:\n",
        "    Merge: function that merges dictionaries\n",
        "    df_data (df): Dataframe to hold the information\n",
        "    output_path (str): Path to save final dataframe\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  label_lst=['Subject','Negation_cue',\n",
        "              'Potential_therapeutic_event',\n",
        "              'Drug','Effect','Adverse_event',\n",
        "              'Race','Age','Gender',\n",
        "              'Population','Disorder','Duration',\n",
        "              'Time_elapsed','Route','Freq',\n",
        "              'Dosage','Combination.Drug','Treat-Disorder',\n",
        "             'Treatment','Severity_cue','Severity',\n",
        "             'Speculation_cue','Sub-Disorder',\n",
        "             ]\n",
        "  \n",
        "  train_path='/content/drive/MyDrive/PHEE/output/train_ann'\n",
        "  dev_path='/content/drive/MyDrive/PHEE/output/dev_ann'\n",
        "  test_path='/content/drive/MyDrive/PHEE/output/test_ann'\n",
        "\n",
        "  for l in label_lst:\n",
        "\n",
        "    with open(train_path+'_{}.pickle'.format(l), 'rb') as handle:\n",
        "        train_d=pickle.load(handle)\n",
        "\n",
        "    with open(dev_path+'_{}.pickle'.format(l), 'rb') as handle:\n",
        "        dev_d=pickle.load(handle)\n",
        "\n",
        "    with open(test_path+'_{}.pickle'.format(l), 'rb') as handle:\n",
        "        test_d=pickle.load(handle)\n",
        "\n",
        "    train_dev_dict=Merge(train_d, dev_d)\n",
        "    final_dict=Merge(train_dev_dict, test_d)\n",
        "\n",
        "    df=pd.DataFrame.from_dict(final_dict,orient='index',columns=[l])\n",
        "    df.reset_index(inplace=True)\n",
        "\n",
        "    df_data=df_data.merge(df,how='left',on='index')\n",
        "\n",
        "  df_data.to_pickle(output_path)\n",
        "\n",
        "  print('The shape of the final data set is: {}'.format(df_data.shape))\n"
      ],
      "metadata": {
        "id": "9kcu4QJzH_L_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "8764f7c9-019e-4775-9590-b212e5a48217"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-9609fc392c05>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    ,'Speculation_cue','Sub-Disorder',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parse the Text and Ann Files**"
      ],
      "metadata": {
        "id": "oRcRWu9ZurUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_train='/content/drive/MyDrive/PHEE/input/clean/train'\n",
        "path_dev='/content/drive/MyDrive/PHEE/input/clean/dev'\n",
        "path_test='/content/drive/MyDrive/PHEE/input/clean/test'\n",
        "\n",
        "parse_txt_file(path_train,'/content/drive/MyDrive/PHEE/output/train_txt.pickle')\n",
        "parse_txt_file(path_dev,'/content/drive/MyDrive/PHEE/output/dev_txt.pickle')\n",
        "parse_txt_file(path_test,'/content/drive/MyDrive/PHEE/output/test_txt.pickle')\n",
        "\n",
        "\n",
        "parse_ann_file(path_train,'/content/drive/MyDrive/PHEE/output/train_ann')\n",
        "parse_ann_file(path_dev,'/content/drive/MyDrive/PHEE/output/dev_ann')\n",
        "parse_ann_file(path_test,'/content/drive/MyDrive/PHEE/output/test_ann')"
      ],
      "metadata": {
        "id": "5uqHFlq3wYBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Parsed File Data and Merge the Text Data**"
      ],
      "metadata": {
        "id": "gmPZhEwPuyMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_txt_dict=pkl_load_dict('/content/drive/MyDrive/PHEE/output/train_txt.pickle')\n",
        "dev_txt_dict=pkl_load_dict('/content/drive/MyDrive/PHEE/output/dev_txt.pickle')\n",
        "test_txt_dict=pkl_load_dict('/content/drive/MyDrive/PHEE/output/test_txt.pickle')"
      ],
      "metadata": {
        "id": "i6nK_TLn6Le4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dev_dict=Merge(train_txt_dict, dev_txt_dict)\n",
        "text_dict=Merge(train_dev_dict, test_txt_dict)\n",
        "df=pd.DataFrame.from_dict(text_dict,orient='index',columns=['Text'])\n",
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "xVS0Kk79-nCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Dataframe of Raw Data**"
      ],
      "metadata": {
        "id": "CJRXAujXu9Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_creation(df,Merge,'/content/drive/MyDrive/PHEE/output/data_df.pkl')"
      ],
      "metadata": {
        "id": "qcyWpVhN-Mzb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
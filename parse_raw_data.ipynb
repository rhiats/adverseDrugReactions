{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15DL5TZ8KCnka9QwcFaEux50ceq_nlu9x",
      "authorship_tag": "ABX9TyMsQY9odS0Ntgi+/LvUO854"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Parse PHEE Data**\n",
        "\n",
        "PHEE data is stored in .txt files and .ann files, which are parsed and saved into dictionaries for future analysis"
      ],
      "metadata": {
        "id": "qmQ0dLFwmTle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "n-n_U3cymUOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_txt_file(input_path,output_path):\n",
        "  \"\"\"\n",
        "    Parse the text files and save the data to .pkl file\n",
        "\n",
        "    @p:\n",
        "    input_path (str): Path of the directory with input data\n",
        "    output_path (str): Path of the directory to save pkl file\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  temp_dict={'id':[],'text':[]}\n",
        "\n",
        "  for file_name in glob.glob(input_path + \"/*.txt\"):\n",
        "    id=file_name.split('.')[0].split('/')[-1]\n",
        "    temp_dict['id'].append(id)\n",
        "\n",
        "    with open(file_name) as f:\n",
        "      lines=f.readlines()[0]\n",
        "    \n",
        "    temp_dict['text'].append(lines)\n",
        "\n",
        "    with open(output_path, 'wb') as handle:\n",
        "      pickle.dump(temp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def concat_ann_file(input_path,output_path):\n",
        "  \"\"\"\n",
        "    Parse the ann files and save the data to .pkl file\n",
        "\n",
        "    @p:\n",
        "    input_path (str): Path of the directory with input data\n",
        "    output_path (str): Path of the directory to save pkl file\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  temp_dict={'id':[],'Subject':[],'Treatment':[],\n",
        "             'Potential_therapeutic_event':[],\n",
        "             'Drug':[],'Effect':[],'Adverse_event':[],\n",
        "             'Race':[],'Age':[],'Gender':[],\n",
        "             'Population':[],'Disorder':[],'Duration':[],\n",
        "             'Time_elapsed':[],'Route':[],'Freq':[],\n",
        "             'Dosage':[],'Combination.Drug':[]}\n",
        "\n",
        "  label_lst=['Subject','Treatment',\n",
        "             'Potential_therapeutic_event',\n",
        "             'Drug','Effect','Adverse_event',\n",
        "             'Race','Age','Gender',\n",
        "             'Population','Disorder','Duration',\n",
        "             'Time_elapsed','Route','Freq',\n",
        "             'Dosage','Combination.Drug']\n",
        "\n",
        "  for file_name in glob.glob(input_path + \"/*.ann\")[0:10]:\n",
        "    id=file_name.split('.')[0].split('/')[-1]\n",
        "\n",
        "    temp_dict['id'].append(id)\n",
        "\n",
        "    ck_cnt=0\n",
        "    \n",
        "\n",
        "    with open(file_name, 'r') as document_anno_file:\n",
        "      lines = document_anno_file.readlines()\n",
        "      \n",
        "      s, t, p, d, e, a, r, ag, g, pop, dis, dur, t_e, rout, freq, dos, com = ([] for i in range(17))\n",
        "\n",
        "      temp_arr_lst=[s, t, p, d, e, a, r, ag, g, pop, dis, dur, t_e, rout, freq, dos, com]\n",
        "\n",
        "      for line in lines:\n",
        "        standoff_line=line.split(\"\\t\")\n",
        "        standoff_line.pop(0)\n",
        "\n",
        "        identifier=standoff_line[0].split()[0].strip()\n",
        "        \n",
        "        if identifier=='Drug': d.append(standoff_line[1].strip())\n",
        "        elif identifier=='Effect': e.append(standoff_line[1].strip())\n",
        "        elif identifier=='Adverse_event': a.append(standoff_line[1].strip())\n",
        "        elif identifier=='Subject': s.append(standoff_line[1].strip())\n",
        "        elif identifier=='Treatment': t.append(standoff_line[1].strip())\n",
        "        elif identifier=='Potential_therapeutic_event': p.append(standoff_line[1].strip())\n",
        "        elif identifier=='Race': r.append(standoff_line[1].strip())\n",
        "        elif identifier=='Age': ag.append(standoff_line[1].strip())\n",
        "        elif identifier=='Gender': g.append(standoff_line[1].strip())\n",
        "        elif identifier=='Population': pop.append(standoff_line[1].strip())\n",
        "        elif identifier=='Disorder': dis.append(standoff_line[1].strip())\n",
        "        elif identifier=='Duration': dur.append(standoff_line[1].strip())\n",
        "        elif identifier=='Time_elapsed': t_e.append(standoff_line[1].strip())\n",
        "        elif identifier=='Route': rout.append(standoff_line[1].strip())\n",
        "        elif identifier=='Freq': freq.append(standoff_line[1].strip())\n",
        "        elif identifier=='Dosage': dos.append(standoff_line[1].strip())\n",
        "        elif identifier=='Combination.Drug': com.append(standoff_line[1].strip())\n",
        "\n",
        "        for i in range(len(label_lst)):\n",
        "          temp_dict[label_lst[i]].append(temp_arr_lst[i])\n",
        "\n",
        "    with open(output_path, 'wb') as handle:\n",
        "      pickle.dump(temp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "9kcu4QJzH_L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_train='/content/drive/MyDrive/PHEE/input/clean/train'\n",
        "path_dev='/content/drive/MyDrive/PHEE/input/clean/dev'\n",
        "path_test='/content/drive/MyDrive/PHEE/input/clean/test'\n",
        "\n",
        "concat_txt_file(path_train,'/content/drive/MyDrive/PHEE/output/train_txt.pickle')\n",
        "concat_txt_file(path_dev,'/content/drive/MyDrive/PHEE/output/dev_txt.pickle')\n",
        "concat_txt_file(path_test,'/content/drive/MyDrive/PHEE/output/test_txt.pickle')\n",
        "concat_ann_file(path_train,'/content/drive/MyDrive/PHEE/output/train_ann.pickle')\n",
        "concat_ann_file(path_dev,'/content/drive/MyDrive/PHEE/output/dev_ann.pickle')\n",
        "concat_ann_file(path_test,'/content/drive/MyDrive/PHEE/output/test_ann.pickle')"
      ],
      "metadata": {
        "id": "5uqHFlq3wYBn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}